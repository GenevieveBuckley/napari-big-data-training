{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image tracking tutorial with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Demo data\n",
    "\n",
    "We use data from the [Cell Tracking Challenge](http://celltrackingchallenge.net/3d-datasets/),\n",
    "specifically:\n",
    "\n",
    "- the [C. elegans developing embryo training\n",
    "  dataset](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CE.zip)\n",
    "  (3GB), **OR**, if that is too large for you to comfortably download,\n",
    "- the [Chinese Hamster Ovarian (CHO) nuclei overexpressing GFP-PCNA training\n",
    "  dataset](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CHO.zip)\n",
    "  (98MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dask.distributed\n",
    "\n",
    "A first life hack: in general, avoid using bare dask, and instead create a `dask.distributed` Client as in the cell below. What this buys you:\n",
    "\n",
    "- a [diagnostics dashboard](https://docs.dask.org/en/latest/diagnostics-distributed.html). This can be invaluable in helping to understand performance in your application. We'll see a live example below.\n",
    "- seamless scaling. Whether the scheduler is using local workers or connected to [your institution's HPC](https://jobqueue.dask.org/en/latest/), or [cloud compute](https://docs.dask.org/en/latest/setup/cloud.html), the API is the same — you just change the scheduler and connect the Client to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about the dask dashboard with:\n",
    "- This introduction to the dask dashboard (20 minute video): https://www.youtube.com/watch?v=N_GqzcuGLCY\n",
    "- This introduction to the jupyterlab extension (5 minute video): https://www.youtube.com/watch?v=EX_voquHdk0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import distributed\n",
    "client = distributed.Client()\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned at the top of this notebook, we will use data from the [Cell Tracking Challenge](http://celltrackingchallenge.net/3d-datasets/),\n",
    "specifically:\n",
    "\n",
    "- the [C. elegans developing embryo training\n",
    "  dataset](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CE.zip)\n",
    "  (3GB), **OR**, if that is too large for you to comfortably download,\n",
    "- the [Chinese Hamster Ovarian (CHO) nuclei overexpressing GFP-PCNA training\n",
    "  dataset](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CHO.zip)\n",
    "  (98MB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image.imread import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please set the path to your data here!\n",
    "ROOT_PATH = '/Users/nsofroniew/GitHub/image-demos/data/cell-tracking/Fluo-N3DH-CE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note you might need a slight downsample here to deal with a known ghosting issue\n",
    "embryo = imread(ROOT_PATH + '01/t*.tif')[:, :, ::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embryo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(embryo, scale=[1, 5, 1, 1])\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:cornflowerblue\">Exercise: file formats</span>\n",
    "\n",
    "Open the dask dashboard, and view it while changing timepoints in napari. How long does loading a tiff file take?\n",
    "\n",
    "If you have enough room in your drive, the [zarr](https://zarr.readthedocs.io/en/stable/) format offers much faster read from disk than tiff, especially for segmentations, which have very effective compression.\n",
    "\n",
    "Use `dask.Array.to_zarr` to save to a zarr file, and reload the array with `dask.array.from_zarr`. Swap out the image layer for the zarr-based one. How long does the load take now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Save data in the zarr file format\n",
    "da.to_zarr(embryo, 'embryo.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Read data from zarr format and view it in napari\n",
    "embryo = da.from_zarr('embryo.zarr')\n",
    "viewer = napari.view_image(embryo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the tracking data\n",
    "\n",
    "Now, let's view the tracking data. The track format is described in [this pdf](https://public.celltrackingchallenge.net/documents/Naming%20and%20file%20content%20conventions.pdf). You can also see a description of the below workflow without dask (ie it *must* fit in your RAM) at [this napari documentation page](https://napari.org/tutorials/applications/cell_tracking).\n",
    "\n",
    "The tracklets are actually individually-labelled pixels within a volume like the original image. napari prefers to display tracks directly from coordinates, so we will use dask to convert from one to the other.\n",
    "\n",
    "We are lucky: the images can be processed one at a time (which dask is perfect for), and the compressed data (just point coordinates) are much, much smaller — easy to fit in RAM. We take advantage of this in the below workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklet_images = imread(ROOT_PATH + '01_GT/TRA/man_track*.tif')[:, : , ::2, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function that will work on an individual volume, together with that volume's index (ie the timepoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops_table\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def image_to_tracklets(volume, idx):\n",
    "    props_dict = regionprops_table(\n",
    "        np.asarray(volume), properties=('label', 'centroid')\n",
    "    )\n",
    "    props_df = pd.DataFrame(props_dict)\n",
    "    props_df['frame'] = idx\n",
    "    return props_df[\n",
    "        ['label', 'frame', 'centroid-0', 'centroid-1', 'centroid-2']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run that function on the whole volume using the `Client.map` API. Futures are little IOUs for computation: a Future may or may not contain the result of the computation. Calling `future.result()` on a Future object causes Python to wait for that result to be ready. Otherwise, creating a Future is more or less instantaneous.\n",
    "\n",
    "We will see later that futures have a `.cancel()` method — useful when you trigger a lot of computation but realise you want to stop it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    image_to_tracklets,\n",
    "    tracklet_images,\n",
    "    np.arange(len(tracklet_images)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets = (\n",
    "    pd.concat(all_tables)\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(['label', 'frame'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets_layer = viewer.add_tracks(tracklets, scale=[1, 5, 1, 1])\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to also load the lineage information, which is presented in a table called `man_track.txt`, containing the following four columns, called LBEP:\n",
    "\n",
    "> - L - a unique label of the track (label of markers, 16-bit positive value)\n",
    "> - B - a zero-based temporal index of the frame in which the track begins\n",
    "> - E - a zero-based temporal index of the frame in which the track ends\n",
    "> - P - label of the parent track (0 is used when no parent is defined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbep = np.loadtxt(\n",
    "    ROOT_PATH + '01_GT/TRA/man_track.txt',\n",
    "    dtype=np.uint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = dict(lbep[:, [0, 3]])\n",
    "graph = {k: v for k, v in full_graph.items() if v != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_layer = viewer.add_tracks(tracklets, graph=graph, scale=[1, 5, 1, 1])\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Our final goal will be to compute a segmentation from the grayscale image together with the points in the tracks. Just like last time, we will use smoothed and thresholded nuclei as a mask, and we will use the track points (conveniently already in marker image format!) to run watershed on each.\n",
    "\n",
    "We can use the `dask-image` library, which contains many functions adapted from `scipy.ndimage`, to do the smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image import ndfilters\n",
    "\n",
    "smoothed = ndfilters.gaussian_filter(\n",
    "    embryo,\n",
    "    sigma=[0, 1, 5, 5],\n",
    ")\n",
    "\n",
    "smoothed_layer = viewer.add_image(\n",
    "    smoothed,\n",
    "    scale=[5, 1, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use [`dask.array.map_blocks`](https://docs.dask.org/en/latest/array-api.html#dask.array.map_blocks) to find the edges of the nuclei, just like in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "\n",
    "edges = da.map_blocks(filters.scharr, smoothed)\n",
    "\n",
    "edges_layer = viewer.add_image(edges, scale=[5, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:cornflowerblue\">Final challenge: distributed segmentation with dask</span>\n",
    "\n",
    "1. Find threshold values for each timepoint of the smoothed data using `client.map` and a scikit-image thresholding function from `skimage.filters`. Create an array of the thresholding values\n",
    "2. Using [NumPy broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html), produce a Dask array containing the thresholded smooth values. Add this array to napari.\n",
    "3. (Optionally) use [`da.map_blocks`](https://docs.dask.org/en/latest/array-api.html#dask.array.map_blocks) with a custom filter function to find better boundaries of the nuclei. Add this array to napari.\n",
    "4. Use [`da.map_blocks`](https://docs.dask.org/en/latest/array-api.html#dask.array.map_blocks) together with `skimage.segmentation.watershed` and the three previous arrays to create the output segmentation. Add this array as label layer to napari.\n",
    "5. Navigate the volume by clicking on the slider, and monitor the Dask dashboard. (Tip: to reduce lag in response time, toggle the visibility OFF for any layers you are not looking at in napari)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Find threshold values for each timepoint of the smoothed data\n",
    "# using client.map and a scikit-image thresholding function from skimage.filters. \n",
    "from skimage import filters\n",
    "\n",
    "def threshold_li(darr):\n",
    "    return filters.threshold_li(np.asarray(darr))\n",
    "\n",
    "futures = client.map(threshold_li, smoothed)\n",
    "thresholds = [f.result() for f in futures]\n",
    "\n",
    "# Create an array of the thresholding values\n",
    "thresholds_for_broadcasting = np.asarray(thresholds).reshape(-1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"thresholds_for_broadcasting.shape\", thresholds_for_broadcasting.shape)\n",
    "print(\"smoothed.shape\", smoothed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Using [NumPy broadcasting, produce a Dask array containing the thresholded smooth values.\n",
    "thresholded = smoothed > thresholds_for_broadcasting\n",
    "\n",
    "# Add this array to napari.\n",
    "viewer.add_image(thresholded, scale=[10, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Use dask.array.map_blocks together with skimage.segmentation.watershed\n",
    "# and the three previous arrays to create the output segmentation.\n",
    "from skimage import segmentation\n",
    "\n",
    "def watershed(edges, markers, mask):\n",
    "    return segmentation.watershed(\n",
    "        np.asarray(edges), np.asarray(markers), mask=np.asarray(mask)\n",
    "    )\n",
    "\n",
    "segmented = da.map_blocks(\n",
    "    watershed,\n",
    "    edges[:195],\n",
    "    tracklet_images[:195],\n",
    "    thresholded[:195]\n",
    ")\n",
    "\n",
    "# Add this array as a label layer to napari.\n",
    "viewer.add_labels(segmented, scale=[10, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
