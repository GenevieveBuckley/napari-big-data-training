{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# out-of-core image analysis with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# needed for %gui qt to work in jupyter book\n",
    "\n",
    "import time\n",
    "time.sleep(5)\n",
    "del time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dask.distributed\n",
    "\n",
    "A first life hack: in general, avoid using bare dask, and instead create a `dask.distributed` Client as in the cell below. What this buys you:\n",
    "\n",
    "- memory management: the distributed scheduler that is automatically created with the default client will launch processes with maximum memory limits. If they exceed those limits, the scheduler will stop sending tasks to them and eventually kill them. In contrast, without `distributed`, you are subject to the same issues as bare Python. It is very easy to freeze your machine.\n",
    "- a [diagnostics dashboard](https://docs.dask.org/en/latest/diagnostics-distributed.html). This can be invaluable in helping to understand performance in your application. We'll see a live example below.\n",
    "- seamless scaling. Whether the scheduler is using local workers or connected to [your institution's HPC](https://jobqueue.dask.org/en/latest/), or [cloud compute](https://docs.dask.org/en/latest/setup/cloud.html), the API is the same — you just change the scheduler and connect the Client to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import distributed\n",
    "client = distributed.Client()\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_image = np.random.random((512, 512))\n",
    "\n",
    "import napari\n",
    "\n",
    "napari.view_image(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# yes we know Janelia has workstations with TB of RAM\n",
    "# We ignore them for variable naming purposes. =P\n",
    "impossible_image = da.random.random(\n",
    "    (40_000, 2_000, 2_000),\n",
    "    chunks=(1, 1_000, 1_000),\n",
    ")\n",
    "\n",
    "print(impossible_image.nbytes / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.view_image(impossible_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with real images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use data from the [Cell Tracking Challenge](http://celltrackingchallenge.net/3d-datasets/),\n",
    "specifically:\n",
    "\n",
    "- the [C. elegans developing embryo training\n",
    "  dataset](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CE.zip)\n",
    "  (3GB), **OR**, if that is too large for you to comfortably download,\n",
    "- the [Chinese Hamster Ovarian (CHO) nuclei overexpressing GFP-PCNA training\n",
    "  dataset](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CHO.zip)\n",
    "  (98MB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image.imread import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/Users/jni/data/Fluo-N3DH-CE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo = imread(ROOT_PATH + '01/t*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embryo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embryo.chunksize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: below, you might want to subsample the embryo with `embryo[:, :, ::2, ::2]` (correspondingly adjusting the scale), if you run into [this issue with ghosting](https://github.com/napari/napari/issues/1507)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(\n",
    "    embryo,\n",
    "    scale=[10, 1, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:cornflowerblue\">Exercise: file formats</span>\n",
    "\n",
    "Open the dask dashboard, and view it while changing timepoints in napari. How long does loading a tiff file take?\n",
    "\n",
    "If you have enough room in your drive, the [zarr](https://zarr.readthedocs.io/en/stable/) format offers much faster read from disk than tiff, especially for segmentations, which have very effective compression.\n",
    "\n",
    "Use `dask.Array.to_zarr` to save to a zarr file, and reload the array with `dask.array.from_zarr`. Swap out the image layer for the zarr-based one. How long does the load take now?\n",
    "\n",
    "You might want to check out the NGFF tutorial, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the tracking data\n",
    "\n",
    "Now, let's view the tracking data. The track format is described in [this pdf](https://public.celltrackingchallenge.net/documents/Naming%20and%20file%20content%20conventions.pdf). You can also see a description of the below workflow without dask (ie it *must* fit in your RAM) at [this napari documentation page](https://napari.org/tutorials/applications/cell_tracking).\n",
    "\n",
    "The tracklets are actually individually-labelled pixels within a volume like the original image. napari prefers to display tracks directly from coordinates, so we will use dask to convert from one to the other.\n",
    "\n",
    "We are lucky: the images can be processed one at a time (which dask is perfect for), and the compressed data (just point coordinates) are much, much smaller — easy to fit in RAM. We take advantage of this in the below workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklet_images = imread(ROOT_PATH + '01_GT/TRA/man_track*.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function that will work on an individual volume, together with that volume's index (ie the timepoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops_table\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def image_to_tracklets(volume, idx):\n",
    "    props_dict = regionprops_table(\n",
    "        np.asarray(volume), properties=('label', 'centroid')\n",
    "    )\n",
    "    props_df = pd.DataFrame(props_dict)\n",
    "    props_df['frame'] = idx\n",
    "    return props_df[\n",
    "        ['label', 'frame', 'centroid-0', 'centroid-1', 'centroid-2']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run that function on the whole volume using the `Client.map` API. Futures are little IOUs for computation: a Future may or may not contain the result of the computation. Calling `future.result()` on a Future object causes Python to wait for that result to be ready. Otherwise, creating a Future is more or less instantaneous.\n",
    "\n",
    "We will see later that futures have a `.cancel()` method — useful when you trigger a lot of computation but realise you want to stop it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    image_to_tracklets,\n",
    "    tracklet_images,\n",
    "    np.arange(len(tracklet_images)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets = (\n",
    "    pd.concat(all_tables)\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(['label', 'frame'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets_layer = viewer.add_tracks(tracklets, scale=[1, 10, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to also load the lineage information, which is presented in a table called `man_track.txt`, containing the following four columns, called LBEP:\n",
    "\n",
    "> - L - a unique label of the track (label of markers, 16-bit positive value)\n",
    "> - B - a zero-based temporal index of the frame in which the track begins\n",
    "> - E - a zero-based temporal index of the frame in which the track ends\n",
    "> - P - label of the parent track (0 is used when no parent is defined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbep = np.loadtxt(\n",
    "    ROOT_PATH + '01_GT/TRA/man_track.txt',\n",
    "    dtype=np.uint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = dict(lbep[:, [0, 3]])\n",
    "graph = {k: v for k, v in full_graph.items() if v != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_layer = viewer.add_tracks(tracklets, graph=graph, scale=[1, 10, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Our final goal will be to compute a segmentation from the grayscale image together with the points in the tracks. Just like last time, we will use smoothed and thresholded nuclei as a mask, and we will use the track points (conveniently already in marker image format!) to run watershed on each.\n",
    "\n",
    "We can use the `dask-image` library, which contains many functions adapted from `scipy.ndimage`, to do the smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image import ndfilters\n",
    "\n",
    "smoothed = ndfilters.gaussian_filter(\n",
    "    embryo,\n",
    "    sigma=[0, 1, 10, 10],\n",
    ")\n",
    "\n",
    "smoothed_layer = viewer.add_image(\n",
    "    smoothed,\n",
    "    scale=[10, 1, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use [`dask.array.map_blocks`](https://docs.dask.org/en/latest/array-api.html#dask.array.map_blocks) to find the edges of the nuclei, just like in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "\n",
    "edges = da.map_blocks(filters.scharr, smoothed)\n",
    "\n",
    "edges_layer = viewer.add_image(edges, scale=[10, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:cornflowerblue\">Final challenge: distributed segmentation with dask</span>\n",
    "\n",
    "- Find threshold values for each timepoint of the smoothed data using `client.map` and a scikit-image thresholding function from `skimage.filters`. Create an array of the thresholding values\n",
    "- Using [NumPy broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html), produce a Dask array containing the thresholded smooth values. Add this array to napari.\n",
    "- (Optionally) use [`da.map_blocks`](https://docs.dask.org/en/latest/array-api.html#dask.array.map_blocks) with a custom filter function to find better boundaries of the nuclei. Add this array to napari.\n",
    "- Use [`da.map_blocks`](https://docs.dask.org/en/latest/array-api.html#dask.array.map_blocks) together with `skimage.segmentation.watershed` and the three previous arrays to create the output segmentation. Add this array as labels to napari.\n",
    "- Navigate the volume by clicking on the slider, and monitor the Dask dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
